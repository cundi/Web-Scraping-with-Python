 Scraping the Data
In the preceding chapter, we built a crawler that follows links to download the web pages we want. This is interesting but not useful—the crawler downloads a web page, and then discards the result. Now, we need to make this crawler achieve something by extracting data from each web page, which is known as **scraping**.  

We will  rst cover a browser extension called Firebug Lite to examine a web page, which you may already be familiar with if you have a web development background. Then, we will walk through three approaches to extract data from a web page using regular expressions, Beautiful Soup and lxml. Finally, the chapter will conclude with a comparison of these three scraping alternatives.  

## Analyzing a web page
To understand how a web page is structured, we can try examining the source code. In most web browsers, the source code of a web page can be viewed by right-clicking on the page and selecting the View page source option:  

图片：略  

The data we are interested in is found in this part of the HTML:  

```html
   <table>
   <tr id="places_national_flag__row"><td class="w2p_fl"><label
     for="places_national_flag"
       id="places_national_flag__label">National Flag:
         </label></td><td class="w2p_fw"><img
           src="/places/static/images/flags/gb.png" /></td><td
             class="w2p_fc"></td></tr>
   ...
   <tr id="places_neighbours__row"><td class="w2p_fl"><label
     for="places_neighbours"
       id="places_neighbours__label">Neighbours: </label></td><td
         class="w2p_fw"><div><a href="/iso/IE">IE </a></div></td><td
           class="w2p_fc"></td></tr></table>
```

This lack of whitespace and formatting is not an issue for a web browser to interpret, but it is dif cult for us. To help us interpret this table, we will use the Firebug Lite extension, which is available for all web browsers at https://getfirebug.com/ firebuglite. Firefox users can install the full Firebug extension if preferred, but the features we will use here, and in Chapter 6, Interacting with Forms on dynamic content, are included in the Lite version.  

Now, with Firebug Lite installed, we can right-click on the part of the web page we are interested in scraping and select Inspect with Firebug Lite from the context menu, as shown here:  

图片：略   


This will open a panel showing the surrounding HTML hierarchy of the selected element:  

图片：略  


In the preceding screenshot, the country attribute was clicked on and the Firebug panel makes it clear that the country area  gure is included within a `<td>` element of class `w2p_fw`, which is the child of a `<tr>` element of ID `places_area__row`. We now have all the information needed to scrape the area data.  

## Three approaches to scrape a web page
Now that we understand the structure of this web page we will investigate three different approaches to scraping its data,  rstly with regular expressions, then with the popular BeautifulSoup module, and  nally with the powerful lxml module.  

## Regular expressions
If you are unfamiliar with regular expressions or need a reminder, there is a thorough overview available at https://docs.python.org/2/howto/regex.html.  

To scrape the area using regular expressions, we will  rst try matching the contents of the <td> element, as follows:  

```python
   >>> import re
   >>> url = 'http://example.webscraping.com/view/UnitedKingdom-239'
   >>> html = download(url)
   >>> re.findall('<td class="w2p_fw">(.*?)</td>', html)

   ['<img src="/places/static/images/flags/gb.png" />',
  '244,820 square kilometres',
  '62,348,447',
  'GB',
  'United Kingdom',
     'London',
     '<a href="/continent/EU">EU</a>',
     '.uk',
     'GBP',
     'Pound',
     '44',
     '@# #@@|@## #@@|@@# #@@|@@## #@@|@#@ #@@|@@#@ #@@|GIR0AA',
     '^(([A-Z]\\d{2}[A-Z]{2})|([A-Z]\\d{3}[A-Z]{2})|([A-Z]{2}\\d{2}A-Z]{2})|([A-Z]{2}\\d{3}[A-Z]{2})|([A-Z]\\d[A-Z]\\d[A-Z]{2})([A-Z]{2}\\d[A-Z]\\d[A-Z]{2})|(GIR0AA))$',
     'en-GB,cy-GB,gd',
     '<div><a href="/iso/IE">IE </a></div>']
```

This result shows that the `<td class="w2p_fw">` tag is used for multiple country attributes. To isolate the area, we can select the second element, as follows:  

```python
   >>> re.findall('<td class="w2p_fw">(.*?)</td>', html)[1]
   '244,820 square kilometres'

```


